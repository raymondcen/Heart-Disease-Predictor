Logistic Regression:
  penalty: ["l1", "l2", "elasticnet"]
  C: [0.05, 0.1, 0.15, 0.2, 0.5, 1, 2]
  l1_ratio: [0.2, 0.3, 0.4, 0.5, 0.6]  # Only used with elasticnet
  solver: ["saga", "liblinear"]  
  # C: [0.2]
  # penalty: ['l2']
  # solver: ['saga']

Random Forest:
  n_estimators: [50, 75, 100]  
  max_depth: [10,15,25]  
  min_samples_split: [10, 15, 20, 25]  
  min_samples_leaf: [5, 8, 10, 12]  
  max_leaf_nodes: [50, 100, 150]
  max_features: ["sqrt", "log2"]  

XGBoost:
  n_estimators: [400, 500, 600, 700, 800]  
  max_depth: [4, 5, 6, 7]  
  learning_rate: [0.08, 0.09, 0.1, 0.11, 0.12]  
  subsample: [0.4, 0.5, 0.6, 0.7]  
  colsample_bytree: [0.7, 0.8, 0.9]  

CatBoost:
  iterations: [500, 750, 1000, 1250]  
  depth: [7, 8, 9, 10]  
  learning_rate: [0.08, 0.09, 0.1, 0.11]  
  l2_leaf_reg: [6, 7, 8, 9]  
  
GradientBoosting:
  n_estimators: [75, 90, 100, 125]  
  learning_rate: [0.08, 0.09, 0.1, 0.11]  
  max_depth: [1, 2, 3]  
  subsample: [0.6, 0.7, 0.8, 0.9]  
  min_samples_leaf: [3, 4, 5]  
